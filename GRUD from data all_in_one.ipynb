{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data loading and preprocess\n",
    "1. data loading\n",
    "2. calculate max values and mean values\n",
    "3. data normalize\n",
    "4. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "import itertools\n",
    "import numbers\n",
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath = './input/set-a/'\n",
    "inputdict = {\n",
    "    \"ALP\" : 0,\n",
    "    \"ALT\" : 1,\n",
    "    \"AST\" : 2,\n",
    "    \"Albumin\" : 3,\n",
    "    \"BUN\" : 4,\n",
    "    \"Bilirubin\" : 5,\n",
    "    \"Cholesterol\" : 6,\n",
    "    \"Creatinine\" : 7,\n",
    "    \"DiasABP\" : 8,\n",
    "    \"FiO2\" : 9,\n",
    "    \"GCS\" : 10,\n",
    "    \"Glucose\" : 11,\n",
    "    \"HCO3\" : 12,\n",
    "    \"HCT\" : 13,\n",
    "    \"HR\" : 14,\n",
    "    \"K\" : 15,\n",
    "    \"Lactate\" : 16,\n",
    "    \"MAP\" : 17,\n",
    "    \"Mg\" : 18,\n",
    "    \"Na\" : 19,\n",
    "    \"PaCO2\" : 20,\n",
    "    \"PaO2\" : 21,\n",
    "    \"Platelets\" : 22,\n",
    "    \"RespRate\" : 23,\n",
    "    \"SaO2\" : 24,\n",
    "    \"SysABP\" : 25,\n",
    "    \"Temp\" : 26,\n",
    "    \"Tropl\" : 27,\n",
    "    \"TroponinI\" : 27, #temp\n",
    "    \"TropT\" : 28,\n",
    "    \"TroponinT\" : 28, #temp\n",
    "    \"Urine\" : 29,\n",
    "    \"WBC\" : 30,\n",
    "    \"Weight\" : 31,\n",
    "    \"pH\" : 32,\n",
    "    \"NIDiasABP\" : 33,\n",
    "    \"NIMAP\" : 34,\n",
    "    \"NISysABP\" : 35,\n",
    "    \"MechVent\" : 36,\n",
    "    \"RecordID\" : 37,\n",
    "    \"Age\" : 38,\n",
    "    \"Gender\" :39,\n",
    "    \"ICUType\" : 40,\n",
    "    \"Height\": 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeparser(time):\n",
    "    return pd.to_timedelta(time + ':00')\n",
    "\n",
    "def timedelta_to_day_figure(timedelta):\n",
    "    return timedelta.days + (timedelta.seconds/86400) #(24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x(df):\n",
    "    grouped_data = df.groupby('Time')\n",
    "    \n",
    "    #generate input vectors\n",
    "    x = np.zeros((len(inputdict)-2, grouped_data.ngroups))\n",
    "\n",
    "    # fill the x and masking vectors\n",
    "    pre_time = pd.to_timedelta(0)\n",
    "    t = 0\n",
    "    for row_index, value in df.iterrows():\n",
    "        '''\n",
    "        t = colum, time frame\n",
    "        agg_no = row, variable\n",
    "        '''\n",
    "        #print(value)\n",
    "        agg_no = inputdict[value.Parameter]\n",
    "\n",
    "        # same timeline check.        \n",
    "        if pre_time != value.Time:\n",
    "            pre_time = value.Time\n",
    "            t += 1\n",
    "            \n",
    "        #print('agg_no : {}\\t t : {}\\t value : {}'.format(agg_no, t, value.Value))\n",
    "        x[agg_no, t] = value.Value    \n",
    "     \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.20500e+03 1.14700e+04 1.84300e+04 5.30000e+00 1.97000e+02 4.77000e+01\n",
      " 3.30000e+02 2.21000e+01 2.68000e+02 1.00000e+00 1.50000e+01 1.14300e+03\n",
      " 5.00000e+01 6.18000e+01 3.00000e+02 2.29000e+01 2.93000e+01 3.00000e+02\n",
      " 9.90000e+00 1.77000e+02 1.00000e+02 5.00000e+02 1.04700e+03 9.80000e+01\n",
      " 1.00000e+02 2.95000e+02 4.21000e+01 4.92000e+01 2.49100e+01 1.10000e+04\n",
      " 1.87500e+02 3.00000e+02 7.35000e+02 2.01000e+02 2.09000e+02 2.96000e+02\n",
      " 1.00000e+00 1.42673e+05 9.00000e+01 1.00000e+00 4.00000e+00 4.31800e+02]\n"
     ]
    }
   ],
   "source": [
    "x_max = np.zeros(len(inputdict) -2)\n",
    "for filename in os.listdir(inputpath):\n",
    "    df = pd.read_csv(inputpath + filename,\\\n",
    "                     header=0,\\\n",
    "                     parse_dates=['Time'],\\\n",
    "                     date_parser=timeparser)\n",
    "    x = df_to_x(df)\n",
    "    temp_x_max = np.max(x.T, axis=0)\n",
    "    x_max = np.maximum(x_max, temp_x_max)\n",
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.205e+03 1.147e+04 1.843e+04 5.300e+00 1.970e+02 4.770e+01 3.300e+02\n",
      " 2.210e+01 2.680e+02 1.000e+00 1.500e+01 1.143e+03 5.000e+01 6.180e+01\n",
      " 3.000e+02 2.290e+01 2.930e+01 3.000e+02 9.900e+00 1.770e+02 1.000e+02\n",
      " 5.000e+02 1.047e+03 9.800e+01 1.000e+02 2.950e+02 4.210e+01 4.920e+01\n",
      " 2.491e+01 1.100e+04 1.875e+02 3.000e+02 7.350e+02]\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "slice_x_max = x_max[:33]\n",
    "print(slice_x_max)\n",
    "print(slice_x_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,)\n",
      "[2.205e+03 1.147e+04 1.843e+04 5.300e+00 1.970e+02 4.770e+01 3.300e+02\n",
      " 2.210e+01 2.680e+02 1.000e+00 1.500e+01 1.143e+03 5.000e+01 6.180e+01\n",
      " 3.000e+02 2.290e+01 2.930e+01 3.000e+02 9.900e+00 1.770e+02 1.000e+02\n",
      " 5.000e+02 1.047e+03 9.800e+01 1.000e+02 2.950e+02 4.210e+01 4.920e+01\n",
      " 2.491e+01 1.100e+04 1.875e+02 3.000e+02 7.350e+02]\n"
     ]
    }
   ],
   "source": [
    "np.save('./input/x_max', slice_x_max)\n",
    "\n",
    "l_x_max = np.load('./input/x_max.npy')\n",
    "print(l_x_max.shape)\n",
    "print(l_x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_sum_x(df, x_sum):\n",
    "    for row_index, value in df.iterrows():\n",
    "        '''\n",
    "        0 : values\n",
    "        1 : # of values observed\n",
    "        agg_no = row, variable\n",
    "        '''\n",
    "        \n",
    "        #print(value)\n",
    "        agg_no = inputdict[value.Parameter]\n",
    "        \n",
    "        x_sum[agg_no, 0] += value.Value\n",
    "        x_sum[agg_no, 1] += 1 \n",
    "\n",
    "    return x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "#generate input vectors\n",
    "x_sum = np.zeros((len(inputdict)-2, 2))\n",
    "\n",
    "for filename in os.listdir(inputpath):\n",
    "    df = pd.read_csv(inputpath + filename,\\\n",
    "                     header=0,\\\n",
    "                     parse_dates=['Time'],\\\n",
    "                     date_parser=timeparser)\n",
    "    x_sum = df_to_sum_x(df, x_sum)\n",
    "print(x_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 1)\n"
     ]
    }
   ],
   "source": [
    "x_mean = x_sum[:,:1]/x_sum[:,1:2]\n",
    "\n",
    "'''print(x_sum[:,:1])\n",
    "print(x_sum[:,1:2])\n",
    "\n",
    "print(x_mean.shape)\n",
    "print(x_mean)'''\n",
    "print(x_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,)\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "x_mean = np.squeeze(x_mean)\n",
    "print(x_mean.shape)\n",
    "#print(x_mean)\n",
    "x_mean = x_mean[:33]\n",
    "print(x_mean.shape)\n",
    "#print(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "np.save('./input/x_mean', x_mean)\n",
    "l_x_mean = np.load('./input/x_mean.npy')\n",
    "print(l_x_mean.shape)\n",
    "#print(l_x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,)\n",
      "[0.05295841 0.03439189 0.02747065 0.55138226 0.13917019 0.060976\n",
      " 0.47429533 0.06809853 0.22123325 0.54520145 0.75991423 0.12380539\n",
      " 0.46231485 0.49642465 0.29172481 0.18062091 0.09982182 0.26580976\n",
      " 0.20483942 0.78573915 0.40474748 0.30083054 0.18224997 0.20126254\n",
      " 0.96637068 0.40236576 0.8790416  0.1453509  0.04811124 0.0109817\n",
      " 0.06757378 0.27795538 0.01018939]\n"
     ]
    }
   ],
   "source": [
    "x_max = np.load('./input/x_max.npy')\n",
    "x_nor_mean = l_x_mean / x_max\n",
    "print(x_nor_mean.shape)\n",
    "print(x_nor_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,)\n",
      "[0.05295841 0.03439189 0.02747065 0.55138226 0.13917019 0.060976\n",
      " 0.47429533 0.06809853 0.22123325 0.54520145 0.75991423 0.12380539\n",
      " 0.46231485 0.49642465 0.29172481 0.18062091 0.09982182 0.26580976\n",
      " 0.20483942 0.78573915 0.40474748 0.30083054 0.18224997 0.20126254\n",
      " 0.96637068 0.40236576 0.8790416  0.1453509  0.04811124 0.0109817\n",
      " 0.06757378 0.27795538 0.01018939]\n"
     ]
    }
   ],
   "source": [
    "np.save('./input/x_nor_mean', x_nor_mean)\n",
    " \n",
    "l_x_nor_mean = np.load('./input/x_nor_mean.npy')\n",
    "print(l_x_nor_mean.shape)\n",
    "print(l_x_nor_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_x_m_d(df, inputdic, size, id_posistion, split, max_input):\n",
    "    grouped_data = df.groupby('Time')\n",
    "    \n",
    "    #generate input vectors\n",
    "    x = np.zeros((len(inputdic)-2, grouped_data.ngroups))\n",
    "    masking = np.zeros((len(inputdic)-2, grouped_data.ngroups))\n",
    "    delta = np.zeros((split, size))\n",
    "    timetable = np.zeros(grouped_data.ngroups)\n",
    "    id = 0\n",
    "    \n",
    "    s_dataset = np.zeros((3, split, size))\n",
    "    \n",
    "    if grouped_data.ngroups > size:\n",
    "        \n",
    "        # fill the x and masking vectors\n",
    "        pre_time = pd.to_timedelta(0)\n",
    "        t = 0\n",
    "        for row_index, value in df.iterrows():\n",
    "            '''\n",
    "            t = colum, time frame\n",
    "            agg_no = row, variable\n",
    "            '''\n",
    "            #print(value)\n",
    "            agg_no = inputdict[value.Parameter]\n",
    "\n",
    "            # same timeline check.        \n",
    "            if pre_time != value.Time:\n",
    "                pre_time = value.Time\n",
    "                t += 1\n",
    "                timetable[t] = timedelta_to_day_figure(value.Time)\n",
    "\n",
    "            #print('agg_no : {}\\t t : {}\\t value : {}'.format(agg_no, t, value.Value))\n",
    "            x[agg_no, t] = value.Value    \n",
    "            masking[agg_no, t] = 1\n",
    "        \n",
    "        # generate random index array \n",
    "        ran_index = np.random.choice(grouped_data.ngroups, size=size, replace=False)\n",
    "        ran_index.sort()\n",
    "        ran_index[0] = 0\n",
    "        ran_index[size-1] = grouped_data.ngroups-1\n",
    "        \n",
    "        # take id for outcome comparing\n",
    "        id = x[id_posistion, 0]\n",
    "        \n",
    "        # remove unnesserly parts(rows)\n",
    "        x = x[:split, :]\n",
    "        masking = masking[:split, :]\n",
    "        \n",
    "        # coulme(time) sampling\n",
    "        x_sample = np.zeros((split, size))\n",
    "        m_sample = np.zeros((split, size))\n",
    "        time_sample = np.zeros(size)\n",
    "\n",
    "        t_x_sample = x_sample.T\n",
    "        t_marsking = m_sample.T\n",
    "        #t_time = t_sample.T\n",
    "        \n",
    "        t_x = x.T\n",
    "        t_m = masking.T\n",
    "        #t_t = t.T\n",
    "\n",
    "        it = np.nditer(ran_index, flags=['f_index'])\n",
    "        while not it.finished:\n",
    "            #print('it.index = {}, it[0] = {}, ran_index = {}'.format(it.index, it[0], ran_index[it.index]))\n",
    "            t_x_sample[it.index] = t_x[it[0]]\n",
    "            t_marsking[it.index] = t_m[it[0]]\n",
    "            time_sample[it.index] = timetable[it[0]]\n",
    "            it.iternext()\n",
    "        \n",
    "        x = x_sample\n",
    "        masking = m_sample\n",
    "        timetable = time_sample\n",
    "        \n",
    "        # normalize the X\n",
    "        nor_x = x/max_input[:, np.newaxis]\n",
    "     \n",
    "        # fill the delta vectors\n",
    "        for index, value in np.ndenumerate(masking):\n",
    "            '''\n",
    "            index[0] = row, agg\n",
    "            index[1] = col, time\n",
    "            '''\n",
    "            if index[1] == 0:\n",
    "                delta[index[0], index[1]] = 0\n",
    "            elif masking[index[0], index[1]-1] == 0:\n",
    "                delta[index[0], index[1]] = timetable[index[1]] - timetable[index[1]-1] + delta[index[0], index[1]-1]\n",
    "            else:\n",
    "                delta[index[0], index[1]] = timetable[index[1]] - timetable[index[1]-1]\n",
    "    \n",
    "    else:\n",
    "                \n",
    "        # fill the x and masking vectors\n",
    "        pre_time = pd.to_timedelta(0)\n",
    "        t = 0\n",
    "        for row_index, value in df.iterrows():\n",
    "            '''\n",
    "            t = colum, time frame\n",
    "            agg_no = row, variable\n",
    "            '''\n",
    "            #print(value)\n",
    "            agg_no = inputdict[value.Parameter]\n",
    "\n",
    "            # same timeline check.        \n",
    "            if pre_time != value.Time:\n",
    "                pre_time = value.Time\n",
    "                t += 1\n",
    "                timetable[t] = timedelta_to_day_figure(value.Time)\n",
    "\n",
    "            #print('agg_no : {}\\t t : {}\\t value : {}'.format(agg_no, t, value.Value))\n",
    "            x[agg_no, t] = value.Value    \n",
    "            masking[agg_no, t] = 1\n",
    "        \n",
    "        # take id for outcome comparing\n",
    "        id = x[id_posistion, 0]\n",
    "        \n",
    "        # remove unnesserly parts(rows)\n",
    "        x = x[:split, :]\n",
    "        masking = masking[:split, :]\n",
    "        \n",
    "        x = np.pad(x, ((0,0), (size-grouped_data.ngroups, 0)), 'constant')\n",
    "        masking = np.pad(masking, ((0,0), (size-grouped_data.ngroups, 0)), 'constant')\n",
    "        timetable = np.pad(timetable, (size-grouped_data.ngroups, 0), 'constant')\n",
    "        \n",
    "        # normalize the X\n",
    "        nor_x = x/max_input[:, np.newaxis]\n",
    "        \n",
    "        # fill the delta vectors\n",
    "        for index, value in np.ndenumerate(masking):\n",
    "            '''\n",
    "            index[0] = row, agg\n",
    "            index[1] = col, time\n",
    "            '''\n",
    "            if index[1] == 0:\n",
    "                delta[index[0], index[1]] = 0\n",
    "            elif masking[index[0], index[1]-1] == 0:\n",
    "                delta[index[0], index[1]] = timetable[index[1]] - timetable[index[1]-1] + delta[index[0], index[1]-1]\n",
    "            else:\n",
    "                delta[index[0], index[1]] = timetable[index[1]] - timetable[index[1]-1]\n",
    "                \n",
    "    s_dataset[0] = x\n",
    "    s_dataset[1] = masking\n",
    "    s_dataset[2] = delta\n",
    "    \n",
    "    return s_dataset, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3, 33, 49)\n",
      "(3, 33, 49)\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [-1.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# def df_to_x_m_d(df, inputdic, size, id_posistion, split, max_input):\n",
    "size = 49\n",
    "id_posistion = 37\n",
    "split = 33\n",
    "dataset = np.zeros((1,3, split, size))\n",
    "max_input = np.load('./input/x_max.npy')\n",
    "\n",
    "for filename in os.listdir(inputpath):\n",
    "    df = pd.read_csv(inputpath + filename,\\\n",
    "                     header=0,\\\n",
    "                     parse_dates=['Time'],\\\n",
    "                     date_parser=timeparser)\n",
    "    s_dataset, id = df_to_x_m_d(df, inputdict, size, id_posistion, split, max_input)\n",
    "    \n",
    "    dataset = np.concatenate((dataset, s_dataset[np.newaxis, :,:,:]))\n",
    "    \n",
    "\n",
    "dataset = dataset[1:, :,:,:]    \n",
    "print(dataset.shape)\n",
    "\n",
    "print(dataset[0].shape)\n",
    "\n",
    "print(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3, 33, 49)\n"
     ]
    }
   ],
   "source": [
    "np.save('./input/dataset', dataset)\n",
    "\n",
    "t_dataset = np.load('./input/dataset.npy')\n",
    "\n",
    "print(t_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142673     34     22    154   2600      1]\n"
     ]
    }
   ],
   "source": [
    "### Y or label data\n",
    "A_outcome = pd.read_csv('./input/Outcomes-a.txt')\n",
    "arr_outcome = A_outcome.values\n",
    "\n",
    "out_max = np.amax(arr_outcome, axis=0)\n",
    "print(out_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76470588e-01  4.54545455e-02  3.24675325e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 4.70588235e-01  3.63636364e-01  5.19480519e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 6.17647059e-01  5.00000000e-01  1.23376623e-01 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " ...\n",
      " [ 2.35294118e-01  2.27272727e-01  7.14285714e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 6.47058824e-01  4.54545455e-01  5.19480519e-02  2.69230769e-03\n",
      "   1.00000000e+00]\n",
      " [ 7.35294118e-01  5.00000000e-01  4.54545455e-02 -3.84615385e-04\n",
      "   0.00000000e+00]]\n",
      "[  34   22  154 2600    1]\n"
     ]
    }
   ],
   "source": [
    "nor_outcomes = arr_outcome/out_max[np.newaxis, :]\n",
    "s_nor_outcomes = nor_outcomes[:,1:]\n",
    "print(s_nor_outcomes)\n",
    "\n",
    "s_out_max = out_max[1:]\n",
    "print(s_out_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76470588e-01  4.54545455e-02  3.24675325e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 4.70588235e-01  3.63636364e-01  5.19480519e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 6.17647059e-01  5.00000000e-01  1.23376623e-01 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " ...\n",
      " [ 2.35294118e-01  2.27272727e-01  7.14285714e-02 -3.84615385e-04\n",
      "   0.00000000e+00]\n",
      " [ 6.47058824e-01  4.54545455e-01  5.19480519e-02  2.69230769e-03\n",
      "   1.00000000e+00]\n",
      " [ 7.35294118e-01  5.00000000e-01  4.54545455e-02 -3.84615385e-04\n",
      "   0.00000000e+00]]\n",
      "[  34   22  154 2600    1]\n"
     ]
    }
   ],
   "source": [
    "s_nor_outcomes = nor_outcomes[:,1:]\n",
    "print(s_nor_outcomes)\n",
    "\n",
    "s_out_max = out_max[1:]\n",
    "print(s_out_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(4000, 5)\n"
     ]
    }
   ],
   "source": [
    "np.save('./input/max_out', s_out_max)\n",
    "np.save('./input/nor_out', s_nor_outcomes)\n",
    "\n",
    "l_max = np.load('./input/max_out.npy')\n",
    "l_out = np.load('./input/nor_out.npy')\n",
    "\n",
    "print(l_max.shape)\n",
    "print(l_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUD(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, x_mean=0,\\\n",
    "                 bias=True, batch_first=False, dropout=0, bidirectional=False):\n",
    "        super(GRUD, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.zeros = torch.autograd.Variable(torch.zeros(input_size))\n",
    "        self.x_mean = torch.autograd.Variable(torch.tensor(x_mean))\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        \n",
    "        if not isinstance(dropout, numbers.Number) or not 0 <= dropout <= 1 or \\\n",
    "                isinstance(dropout, bool):\n",
    "            raise ValueError(\"dropout should be a number in range [0, 1] \"\n",
    "                             \"representing the probability of an element being \"\n",
    "                             \"zeroed\")\n",
    "        if dropout > 0 and num_layers == 1:\n",
    "            warnings.warn(\"dropout option adds dropout after all but last \"\n",
    "                          \"recurrent layer, so non-zero dropout expects \"\n",
    "                          \"num_layers greater than 1, but got dropout={} and \"\n",
    "                          \"num_layers={}\".format(dropout, num_layers))\n",
    "        \n",
    "        ################################\n",
    "        gate_size = 1 # not used\n",
    "        ################################\n",
    "        \n",
    "        self._all_weights = []\n",
    "        for layer in range(num_layers):\n",
    "            for direction in range(num_directions):\n",
    "                # not used\n",
    "                layer_input_size = input_size if layer == 0 else hidden_size * num_directions\n",
    "             \n",
    "                # decay rates gamma\n",
    "                w_dg_x = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                w_dg_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                                \n",
    "                # z\n",
    "                w_xz = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                w_hz = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                w_mz = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                \n",
    "                # r\n",
    "                w_xr = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                w_hr = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                w_mr = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                \n",
    "                # h_tilde\n",
    "                w_xh = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                w_hh = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                w_mh = torch.nn.Parameter(torch.Tensor(input_size))\n",
    "                \n",
    "                # y (output)\n",
    "                w_hy = torch.nn.Parameter(torch.Tensor(output_size, hidden_size))\n",
    "                \n",
    "                # bias\n",
    "                b_dg_x = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                b_dg_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                b_z = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                b_r = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                b_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n",
    "                b_y = torch.nn.Parameter(torch.Tensor(output_size))\n",
    "                \n",
    "                layer_params = (w_dg_x, w_dg_h,\\\n",
    "                                w_xz, w_hz, w_mz,\\\n",
    "                                w_xr, w_hr, w_mr,\\\n",
    "                                w_xh, w_hh, w_mh,\\\n",
    "                                w_hy,\\\n",
    "                                b_dg_x, b_dg_h, b_z, b_r, b_h, b_y)\n",
    "                \n",
    "                suffix = '_reverse' if direction == 1 else ''\n",
    "                param_names = ['weight_dg_x_l{}{}', 'weight_dg_h_l{}{}',\\\n",
    "                               'weight_xz_l{}{}', 'weight_hz_l{}{}','weight_mz_l{}{}',\\\n",
    "                               'weight_xr_l{}{}', 'weight_hr_l{}{}','weight_mr_l{}{}',\\\n",
    "                               'weight_xh_l{}{}', 'weight_hh_l{}{}','weight_mh_l{}{}',\\\n",
    "                               'weight_hy']\n",
    "                if bias:\n",
    "                    param_names += ['bias_dg_x_l{}{}', 'bias_dg_h_l{}{}',\\\n",
    "                                    'bias_z_l{}{}',\\\n",
    "                                    'bias_r_l{}{}',\\\n",
    "                                    'bias_h_l{}{}',\\\n",
    "                                    'bias_y']\n",
    "                param_names = [x.format(layer, suffix) for x in param_names]\n",
    "\n",
    "                for name, param in zip(param_names, layer_params):\n",
    "                    setattr(self, name, param)\n",
    "                self._all_weights.append(param_names)\n",
    "        \n",
    "        self.flatten_parameters()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def flatten_parameters(self):\n",
    "        \"\"\"\n",
    "        Resets parameter data pointer so that they can use faster code paths.\n",
    "        Right now, this works only if the module is on the GPU and cuDNN is enabled.\n",
    "        Otherwise, it's a no-op.\n",
    "        \"\"\"\n",
    "        any_param = next(self.parameters()).data\n",
    "        if not any_param.is_cuda or not torch.backends.cudnn.is_acceptable(any_param):\n",
    "            return\n",
    "\n",
    "        # If any parameters alias, we fall back to the slower, copying code path. This is\n",
    "        # a sufficient check, because overlapping parameter buffers that don't completely\n",
    "        # alias would break the assumptions of the uniqueness check in\n",
    "        # Module.named_parameters().\n",
    "        all_weights = self._flat_weights\n",
    "        unique_data_ptrs = set(p.data_ptr() for p in all_weights)\n",
    "        if len(unique_data_ptrs) != len(all_weights):\n",
    "            return\n",
    "\n",
    "        with torch.cuda.device_of(any_param):\n",
    "            import torch.backends.cudnn.rnn as rnn\n",
    "\n",
    "            # NB: This is a temporary hack while we still don't have Tensor\n",
    "            # bindings for ATen functions\n",
    "            with torch.no_grad():\n",
    "                # NB: this is an INPLACE function on all_weights, that's why the\n",
    "                # no_grad() is necessary.\n",
    "                torch._cudnn_rnn_flatten_weight(\n",
    "                    all_weights, (4 if self.bias else 2),\n",
    "                    self.input_size, rnn.get_cudnn_mode(self.mode), self.hidden_size, self.num_layers,\n",
    "                    self.batch_first, bool(self.bidirectional))\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        ret = super(GRUD, self)._apply(fn)\n",
    "        self.flatten_parameters()\n",
    "        return ret\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
    "\n",
    "    def check_forward_args(self, input, hidden, batch_sizes):\n",
    "        is_input_packed = batch_sizes is not None\n",
    "        expected_input_dim = 2 if is_input_packed else 3\n",
    "        if input.dim() != expected_input_dim:\n",
    "            raise RuntimeError(\n",
    "                'input must have {} dimensions, got {}'.format(\n",
    "                    expected_input_dim, input.dim()))\n",
    "        if self.input_size != input.size(-1):\n",
    "            raise RuntimeError(\n",
    "                'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n",
    "                    self.input_size, input.size(-1)))\n",
    "\n",
    "        if is_input_packed:\n",
    "            mini_batch = int(batch_sizes[0])\n",
    "        else:\n",
    "            mini_batch = input.size(0) if self.batch_first else input.size(1)\n",
    "\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        expected_hidden_size = (self.num_layers * num_directions,\n",
    "                                mini_batch, self.hidden_size)\n",
    "        \n",
    "        def check_hidden_size(hx, expected_hidden_size, msg='Expected hidden size {}, got {}'):\n",
    "            if tuple(hx.size()) != expected_hidden_size:\n",
    "                raise RuntimeError(msg.format(expected_hidden_size, tuple(hx.size())))\n",
    "\n",
    "        if self.mode == 'LSTM':\n",
    "            check_hidden_size(hidden[0], expected_hidden_size,\n",
    "                              'Expected hidden[0] size {}, got {}')\n",
    "            check_hidden_size(hidden[1], expected_hidden_size,\n",
    "                              'Expected hidden[1] size {}, got {}')\n",
    "        else:\n",
    "            check_hidden_size(hidden, expected_hidden_size)\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        s = '{input_size}, {hidden_size}'\n",
    "        if self.num_layers != 1:\n",
    "            s += ', num_layers={num_layers}'\n",
    "        if self.bias is not True:\n",
    "            s += ', bias={bias}'\n",
    "        if self.batch_first is not False:\n",
    "            s += ', batch_first={batch_first}'\n",
    "        if self.dropout != 0:\n",
    "            s += ', dropout={dropout}'\n",
    "        if self.bidirectional is not False:\n",
    "            s += ', bidirectional={bidirectional}'\n",
    "        return s.format(**self.__dict__)\n",
    "    \n",
    "    \n",
    "    def __setstate__(self, d):\n",
    "        super(GRUD, self).__setstate__(d)\n",
    "        if 'all_weights' in d:\n",
    "            self._all_weights = d['all_weights']\n",
    "        if isinstance(self._all_weights[0][0], str):\n",
    "            return\n",
    "        num_layers = self.num_layers\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        self._all_weights = []\n",
    "        for layer in range(num_layers):\n",
    "            for direction in range(num_directions):\n",
    "                suffix = '_reverse' if direction == 1 else ''\n",
    "                weights = ['weight_dg_x_l{}{}', 'weight_dg_h_l{}{}',\\\n",
    "                           'weight_xz_l{}{}', 'weight_hz_l{}{}','weight_mz_l{}{}',\\\n",
    "                           'weight_xr_l{}{}', 'weight_hr_l{}{}','weight_mr_l{}{}',\\\n",
    "                           'weight_xh_l{}{}', 'weight_hh_l{}{}','weight_mh_l{}{}',\\\n",
    "                           'weight_hy',\\\n",
    "                           'bias_dg_x_l{}{}', 'bias_dg_h_l{}{}',\\\n",
    "                           'bias_z_l{}{}', 'bias_r_l{}{}', 'bias_h_l{}{}','bias_y']\n",
    "                weights = [x.format(layer, suffix) for x in weights]\n",
    "                if self.bias:\n",
    "                    self._all_weights += [weights]\n",
    "                else:\n",
    "                    self._all_weights += [weights[:2]]\n",
    "\n",
    "    @property\n",
    "    def _flat_weights(self):\n",
    "        return list(self._parameters.values())\n",
    "\n",
    "    @property\n",
    "    def all_weights(self):\n",
    "        return [[getattr(self, weight) for weight in weights] for weights in self._all_weights]\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # input.size = (3, 33,49) : num_input or num_hidden, num_layer or step\n",
    "        X = torch.squeeze(input[0]) # .size = (33,49)\n",
    "        Mask = torch.squeeze(input[1]) # .size = (33,49)\n",
    "        Delta = torch.squeeze(input[2]) # .size = (33,49)\n",
    "        Hidden_State = torch.autograd.Variable(torch.zeros(input_size))\n",
    "        \n",
    "        step_size = X.size(1) # 49\n",
    "        #print('step size : ', step_size)\n",
    "        \n",
    "        output = None\n",
    "        h = Hidden_State\n",
    "        for layer in range(num_layers):\n",
    "            \n",
    "            x = torch.squeeze(X[:,layer:layer+1])\n",
    "            m = torch.squeeze(Mask[:,layer:layer+1])\n",
    "            d = torch.squeeze(Delta[:,layer:layer+1])\n",
    "            \n",
    "            # decay rates gamma\n",
    "            w_dg_x = getattr(self, 'weight_dg_x_l' + str(layer))\n",
    "            w_dg_h = getattr(self, 'weight_dg_h_l' + str(layer))\n",
    "                                \n",
    "            #z\n",
    "            w_xz = getattr(self, 'weight_xz_l' + str(layer))\n",
    "            w_hz = getattr(self, 'weight_hz_l' + str(layer))\n",
    "            w_mz = getattr(self, 'weight_mz_l' + str(layer))\n",
    "                \n",
    "            # r\n",
    "            w_xr = getattr(self, 'weight_xr_l' + str(layer))\n",
    "            w_hr = getattr(self, 'weight_hr_l' + str(layer))\n",
    "            w_mr = getattr(self, 'weight_mr_l' + str(layer))\n",
    "                \n",
    "            # h_tilde\n",
    "            w_xh = getattr(self, 'weight_xh_l' + str(layer))\n",
    "            w_hh = getattr(self, 'weight_hh_l' + str(layer))\n",
    "            w_mh = getattr(self, 'weight_mh_l' + str(layer))\n",
    "                \n",
    "            # bias\n",
    "            b_dg_x = getattr(self, 'bias_dg_x_l' + str(layer))\n",
    "            b_dg_h = getattr(self, 'bias_dg_h_l' + str(layer))\n",
    "            b_z = getattr(self, 'bias_z_l' + str(layer))\n",
    "            b_r = getattr(self, 'bias_r_l' + str(layer))\n",
    "            b_h = getattr(self, 'bias_h_l' + str(layer))\n",
    "            \n",
    "            #(4)\n",
    "            gamma_x = torch.exp(-torch.max(self.zeros, (w_dg_x * x + b_dg_x)))\n",
    "            gamma_h = torch.exp(-torch.max(self.zeros, (w_dg_h * h + b_dg_h)))\n",
    "\n",
    "            #(5)\n",
    "            x = m * x + (1 - m) * (gamma_x * x + (1 - gamma_x) * self.x_mean)\n",
    "\n",
    "            #(6)\n",
    "            h = gamma_h * h\n",
    "\n",
    "            z = torch.nn.functional.sigmoid((w_xz*x + w_hz*h + w_mz*m + b_z))\n",
    "            r = torch.nn.functional.sigmoid((w_xr*x + w_hr*h + w_mr*m + b_r))\n",
    "            h_tilde = torch.nn.functional.tanh((w_xh*x + w_hh*(gamma_h * h) + w_mh*m + b_h))\n",
    "            h = (1 - z) * h + z * h_tilde \n",
    "            \n",
    "        w_hy = getattr(self, 'weight_hy')\n",
    "        b_y = getattr(self, 'bias_y')\n",
    "\n",
    "        output = torch.matmul(w_hy, h) + b_y\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_dataloader(dataset, outcomes,\\\n",
    "                    train_proportion = 0.7,\\\n",
    "                    dev_proportion = 0.15):\n",
    "    \n",
    "    train_index = int(np.floor(dataset.shape[0] * train_proportion))\n",
    "    dev_index = int(np.floor(dataset.shape[0] * (train_proportion + dev_proportion)))\n",
    "    \n",
    "    print('train_index : {}'.format(train_index))\n",
    "    print('dev_index : {}'.format(dev_index))\n",
    "    \n",
    "    # split dataset to tarin/dev/test set\n",
    "    train_data, train_label = dataset[:train_index, :,:,:], outcomes[:train_index, :]\n",
    "    dev_data, dev_label = dataset[train_index:dev_index, :,:,:], outcomes[train_index:dev_index, :]\n",
    "    test_data, test_label = dataset[dev_index:, :,:,:], outcomes[dev_index:, :]\n",
    "    \n",
    "    print(\"train_data.shape : {}\".format(train_data.shape))\n",
    "    print(train_label.shape)\n",
    "    print(dev_data.shape)\n",
    "    print(dev_label.shape)\n",
    "    print(test_data.shape)\n",
    "    print(test_label.shape)    \n",
    "    \n",
    "    # ndarray to tensor\n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    dev_data, dev_label = torch.Tensor(dev_data), torch.Tensor(dev_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "    \n",
    "    print(test_data.shape)\n",
    "    print(test_label.shape)\n",
    "    \n",
    "    # tensor to dataset\n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    dev_dataset = utils.TensorDataset(dev_data, dev_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    \n",
    "    # dataset to dataloader \n",
    "    train_dataloader = utils.DataLoader(train_dataset)\n",
    "    dev_dataloader = utils.DataLoader(dev_dataset)\n",
    "    test_dataloader = utils.DataLoader(test_dataset)\n",
    "    \n",
    "    return train_dataloader, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3, 33, 49)\n",
      "(4000, 5)\n",
      "train_index : 3800\n",
      "dev_index : 3900\n",
      "train_data.shape : (3800, 3, 33, 49)\n",
      "(3800, 5)\n",
      "(100, 3, 33, 49)\n",
      "(100, 5)\n",
      "(100, 3, 33, 49)\n",
      "(100, 5)\n",
      "torch.Size([100, 3, 33, 49])\n",
      "torch.Size([100, 5])\n"
     ]
    }
   ],
   "source": [
    "t_dataset = np.load('./input/dataset.npy')\n",
    "t_out = np.load('./input/nor_out.npy')\n",
    "\n",
    "print(t_dataset.shape)\n",
    "print(t_out.shape)\n",
    "\n",
    "train_dataloader, dev_dataloader, test_dataloader = data_dataloader(t_dataset, t_out, train_proportion=0.95, dev_proportion=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "in the paper : 49 layers, 33 input, 18838 parameters\n",
    "input : 10-weights(*input), 6 - biases\n",
    "Y: 1 weight(hidden*output), 1 bias(output)\n",
    "Input : hidden : output : layer  = # of parameters : len(para)\n",
    "1:1:1:1 = 18 : 18\n",
    "2:1:1:1 = 25 : 18  // +7 as expected\n",
    "1:1:1:2 = 34 : 18 // 34 = 16*2 + 2\n",
    "33:33:1:1 = 562 : 18 // 16*33(528) + 33*1 +1 = 562\n",
    "33:33:5:1 = 698 : 18 // 16*33(528) + 33*5(165) +5 = 698\n",
    "33:33:5:49 = 26042 : 18 // 16*33*49(25872) + 33*5(165) +5 = 698\n",
    "weights = 10*33*49(16170) + 33*5(165) = 16335 gap : 2503\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUD is ready\n",
      "number of parameters :  26042\n"
     ]
    }
   ],
   "source": [
    "input_size = 33\n",
    "hidden_size = 33\n",
    "output_size = 5\n",
    "num_layers = 49\n",
    "num_epochs = 1\n",
    "\n",
    "x_mean = torch.Tensor(np.load('./input/x_nor_mean.npy'))\n",
    "\n",
    "model = GRUD(input_size = input_size, hidden_size= hidden_size, output_size= output_size, x_mean=x_mean, num_layers=num_layers)\n",
    "\n",
    "count = count_parameters(model)\n",
    "print('number of parameters : ' , count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8616, 1.0000, 1.0000, 1.0000, 1.0000, 0.8998, 1.0000, 0.9764, 1.0000,\n",
      "        0.9949, 1.0000, 1.0000, 1.0000, 0.8829, 1.0000, 0.8993, 0.9079, 1.0000,\n",
      "        1.0000, 0.9744, 1.0000, 0.9344, 0.9033, 0.9631, 0.9972, 1.0000, 0.9788,\n",
      "        1.0000, 1.0000, 0.9640, 1.0000, 0.8341, 0.8559],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.5972e-01, 9.6169e-01, 1.0000e+00, 8.6589e-01, 8.4198e-01, 1.0000e+00,\n",
      "        9.1550e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9336e-01, 9.0519e-01,\n",
      "        1.0000e+00, 1.0000e+00, 6.9598e-01, 1.0000e+00, 9.5452e-01, 9.4956e-01,\n",
      "        9.0602e-01, 1.0000e+00, 8.7835e-01, 8.6974e-01, 1.0000e+00, 8.3171e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.6287e-02, 9.3333e-01, 9.8132e-01, 1.3312e-43,\n",
      "        1.0000e+00, 1.0000e+00, 8.5530e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9794, 1.0000, 1.0000, 0.8670, 1.0000, 0.8984, 1.0000, 1.0000,\n",
      "        1.0000, 0.8865, 1.0000, 0.8646, 0.9778, 1.0000, 0.8918, 0.9830, 0.9980,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9661, 0.8580, 1.0000,\n",
      "        0.8997, 0.8538, 1.0000, 1.0000, 0.9175, 0.9328],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9925, 1.0000, 1.0000, 1.0000, 0.9498, 1.0000, 1.0000, 0.8407, 1.0000,\n",
      "        1.0000, 0.9031, 1.0000, 1.0000, 0.8433, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.8440, 1.0000, 1.0000, 0.9758, 1.0000, 1.0000, 0.8828, 1.0000, 0.9027,\n",
      "        0.8967, 1.0000, 0.2957, 1.0000, 0.9086, 0.8808],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 8.9534e-01, 1.0000e+00, 1.0000e+00, 9.0590e-01, 1.0000e+00,\n",
      "        1.0000e+00, 9.8079e-01, 8.4259e-01, 8.9592e-01, 8.5220e-01, 8.9748e-01,\n",
      "        9.6579e-01, 1.0000e+00, 7.4106e-03, 9.8128e-01, 1.0000e+00, 9.1531e-01,\n",
      "        1.0000e+00, 8.8033e-01, 8.7473e-01, 9.7762e-01, 9.7778e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.1000e-01, 1.0000e+00, 8.4157e-12,\n",
      "        1.0000e+00, 8.9896e-01, 9.8616e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8532, 1.0000, 1.0000, 0.9024, 0.9063, 1.0000, 0.8421, 0.8934, 0.8531,\n",
      "        0.9558, 0.8447, 0.9909, 0.9779, 1.0000, 1.0000, 0.9628, 1.0000, 0.9396,\n",
      "        0.8861, 0.9386, 1.0000, 0.9782, 1.0000, 0.9733, 0.9597, 0.9675, 1.0000,\n",
      "        1.0000, 0.9877, 1.0000, 1.0000, 0.9362, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8448, 0.9018, 0.9968, 1.0000, 0.8683, 1.0000, 0.8484, 0.9220, 0.9688,\n",
      "        1.0000, 0.4443, 0.8736, 0.9214, 0.9243, 1.0000, 0.9017, 0.9581, 1.0000,\n",
      "        1.0000, 0.9479, 0.9346, 0.9621, 0.9698, 0.1352, 0.9880, 0.9243, 1.0000,\n",
      "        0.9685, 1.0000, 0.0240, 1.0000, 1.0000, 0.8524],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.7769e-01, 9.8131e-01, 1.0000e+00, 9.1011e-01, 8.5858e-01, 9.0034e-01,\n",
      "        8.9733e-01, 9.5288e-01, 8.6054e-01, 9.3269e-01, 8.7349e-01, 1.0000e+00,\n",
      "        1.0000e+00, 9.4948e-01, 2.5510e-05, 9.2448e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 8.5525e-01, 9.2272e-01, 9.2152e-01, 1.0000e+00,\n",
      "        9.1569e-01, 1.0000e+00, 1.0000e+00, 8.5710e-01, 1.0000e+00, 8.5046e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9347, 1.0000, 0.9673, 0.9605, 0.9312, 0.9332, 0.8686, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9122, 1.0000, 1.0000, 1.0000, 0.9337, 0.9658, 1.0000,\n",
      "        0.8590, 0.8815, 0.8952, 1.0000, 0.8883, 1.0000, 0.9331, 0.8427, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.9801, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9456, 1.0000, 0.8578, 0.9312, 1.0000, 1.0000, 1.0000, 0.8827,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.8639, 1.0000, 1.0000, 1.0000, 0.9192,\n",
      "        1.0000, 0.9969, 1.0000, 1.0000, 0.9527, 0.1778, 1.0000, 0.9126, 0.0077,\n",
      "        1.0000, 0.9186, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6518e-01, 9.6821e-01, 1.0000e+00,\n",
      "        9.4764e-01, 9.5574e-01, 1.0000e+00, 9.4190e-01, 9.3889e-01, 1.0000e+00,\n",
      "        9.6818e-01, 9.3357e-01, 3.2496e-05, 9.6885e-01, 1.0000e+00, 8.4361e-01,\n",
      "        9.4913e-01, 9.8817e-01, 1.0000e+00, 8.8378e-01, 8.7335e-01, 1.0000e+00,\n",
      "        8.6607e-01, 9.8778e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.5513e-03,\n",
      "        8.9453e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.8605e-01, 1.0000e+00, 9.2149e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8006e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0246e-02, 3.4877e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 2.8455e-04, 8.4963e-01, 1.0000e+00, 1.9487e-13, 1.0000e+00,\n",
      "        1.0000e+00, 9.1125e-01, 1.0000e+00, 9.8304e-01, 1.0000e+00, 3.4034e-03,\n",
      "        1.6401e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8565, 1.0000, 0.9237, 1.0000, 1.0000, 0.8827, 0.9295, 1.0000, 0.8680,\n",
      "        0.8513, 0.5981, 0.8634, 1.0000, 1.0000, 0.0001, 1.0000, 0.9749, 1.0000,\n",
      "        0.9176, 0.8967, 1.0000, 0.8749, 1.0000, 1.0000, 1.0000, 1.0000, 0.1093,\n",
      "        0.9252, 1.0000, 0.0222, 1.0000, 1.0000, 0.8763],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8638, 0.9549, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9477,\n",
      "        1.0000, 0.9794, 0.9012, 1.0000, 1.0000, 0.0001, 0.9148, 1.0000, 0.9574,\n",
      "        1.0000, 0.9306, 1.0000, 0.9211, 1.0000, 0.5779, 0.9348, 1.0000, 1.0000,\n",
      "        1.0000, 0.9566, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9649, 0.8942, 0.8452, 1.0000, 1.0000, 0.9367,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9728, 1.0000, 0.9670, 1.0000, 0.9278,\n",
      "        0.8560, 0.8733, 0.9931, 1.0000, 1.0000, 0.1821, 1.0000, 1.0000, 1.0000,\n",
      "        0.8678, 1.0000, 0.0011, 0.9205, 1.0000, 0.8783],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9052, 0.9492, 1.0000, 1.0000, 0.9667, 1.0000, 1.0000, 0.8422, 1.0000,\n",
      "        1.0000, 0.9628, 1.0000, 0.9736, 0.8952, 1.0000, 0.9670, 1.0000, 1.0000,\n",
      "        1.0000, 0.9873, 0.9797, 1.0000, 0.9527, 1.0000, 0.8424, 0.9219, 1.0000,\n",
      "        0.9520, 0.8730, 1.0000, 0.8429, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9844, 0.9478, 1.0000, 1.0000, 1.0000, 0.9193,\n",
      "        1.0000, 0.3061, 1.0000, 0.9562, 1.0000, 1.0000, 0.9053, 1.0000, 1.0000,\n",
      "        0.9129, 1.0000, 0.8741, 0.9395, 0.9045, 1.0000, 0.9481, 0.8610, 0.1100,\n",
      "        0.8987, 1.0000, 1.0000, 1.0000, 1.0000, 0.9050],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9812, 0.9537, 1.0000, 0.8740, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9770, 0.9169, 0.9186, 1.0000, 1.0000, 0.0227, 0.9992, 0.9085, 0.9066,\n",
      "        0.8953, 1.0000, 1.0000, 1.0000, 0.9993, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9221, 0.8451, 0.8557, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8625, 1.0000, 0.8417, 1.0000, 0.9432, 0.9708, 0.9009, 1.0000,\n",
      "        1.0000, 0.9457, 1.0000, 0.9955, 0.8808, 0.0042, 0.9057, 0.8504, 0.9369,\n",
      "        1.0000, 1.0000, 1.0000, 0.9448, 0.8718, 1.0000, 1.0000, 0.9317, 0.9581,\n",
      "        0.8906, 0.8769, 1.0000, 0.8684, 0.9498, 0.8433],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8614, 1.0000, 1.0000, 0.9533, 0.8959, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9506, 1.0000, 0.8900, 1.0000, 0.8477, 0.0030, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9287, 1.0000, 1.0000, 0.9352, 1.0000, 0.8892, 0.9635, 0.8959,\n",
      "        1.0000, 0.9331, 0.9505, 0.8751, 0.9176, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woare\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Users\\woare\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([33])\n",
      "tensor([0.9319, 0.9480, 0.9065, 1.0000, 1.0000, 0.8415, 0.9958, 0.9187, 1.0000,\n",
      "        1.0000, 1.0000, 0.9104, 1.0000, 0.9097, 1.0000, 1.0000, 0.8955, 1.0000,\n",
      "        0.8949, 1.0000, 1.0000, 0.9314, 1.0000, 0.7902, 0.9099, 0.8410, 0.0800,\n",
      "        1.0000, 1.0000, 0.0103, 0.9671, 0.9689, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8645, 0.9728, 1.0000, 1.0000, 1.0000, 0.9200, 0.9923, 0.9908,\n",
      "        0.9466, 1.0000, 1.0000, 0.9288, 0.9893, 0.0866, 1.0000, 0.9960, 0.9903,\n",
      "        1.0000, 0.9002, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9786, 1.0000,\n",
      "        0.9333, 1.0000, 1.0000, 0.8742, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9076, 0.8914, 0.9285, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9016, 1.0000, 1.0000, 1.0000, 0.9090, 0.8824, 1.0000,\n",
      "        0.8765, 0.8851, 1.0000, 1.0000, 0.9595, 0.0399, 1.0000, 0.9429, 0.8870,\n",
      "        0.8472, 0.9018, 1.0000, 0.9965, 0.9110, 0.8430],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8936, 1.0000, 0.9781, 1.0000,\n",
      "        0.9226, 1.0000, 0.8984, 0.8636, 0.8621, 1.0000, 0.8724, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8858, 0.9835, 1.0000,\n",
      "        1.0000, 0.9015, 1.0000, 0.9273, 0.8948, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9272, 0.9020, 1.0000, 0.8560, 1.0000, 0.9506, 0.8634, 1.0000, 0.9255,\n",
      "        1.0000, 0.1704, 1.0000, 0.9041, 0.9855, 0.0025, 1.0000, 1.0000, 0.8729,\n",
      "        1.0000, 0.9281, 0.8460, 0.9622, 1.0000, 0.0286, 0.8855, 0.9856, 0.0294,\n",
      "        0.9266, 0.8791, 1.0000, 0.9635, 0.8580, 0.9760],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9041, 1.0000, 1.0000, 0.9350, 0.8952, 1.0000, 1.0000, 1.0000, 0.9147,\n",
      "        1.0000, 1.0000, 1.0000, 0.8759, 0.9344, 1.0000, 1.0000, 1.0000, 0.8545,\n",
      "        0.9758, 1.0000, 1.0000, 0.8494, 1.0000, 0.9723, 0.8568, 0.8492, 1.0000,\n",
      "        1.0000, 0.9480, 0.0001, 0.8596, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9071, 0.9368, 1.0000, 1.0000, 0.8999, 1.0000, 1.0000, 0.8768, 0.8694,\n",
      "        0.9288, 0.9413, 0.8547, 0.8732, 1.0000, 1.0000, 0.9312, 1.0000, 0.8603,\n",
      "        0.9697, 1.0000, 0.8646, 1.0000, 1.0000, 1.0000, 1.0000, 0.8715, 0.8915,\n",
      "        0.9185, 0.9530, 1.0000, 0.9461, 0.9816, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8919, 0.9683, 0.9834, 1.0000, 0.8411, 0.8432, 1.0000, 0.9317, 0.9629,\n",
      "        0.8955, 1.0000, 1.0000, 1.0000, 1.0000, 0.9572, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9265, 1.0000, 1.0000, 0.8437, 1.0000, 1.0000, 0.9469, 1.0000,\n",
      "        0.8798, 0.8662, 1.0000, 0.8655, 0.8738, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.6233e-01, 8.8118e-01, 1.0000e+00, 9.3292e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.4864e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.7136e-01, 8.8900e-01, 3.2268e-06, 1.0000e+00, 9.6556e-01, 1.0000e+00,\n",
      "        9.9647e-01, 9.6567e-01, 1.0000e+00, 9.5861e-01, 8.8692e-01, 2.0763e-01,\n",
      "        8.9826e-01, 1.0000e+00, 5.6037e-01, 1.0000e+00, 1.0000e+00, 9.0951e-01,\n",
      "        9.1410e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9853, 1.0000, 0.9084, 0.9561, 0.9494, 1.0000,\n",
      "        0.8580, 1.0000, 0.8992, 1.0000, 1.0000, 0.8849, 1.0000, 0.9392, 0.9921,\n",
      "        1.0000, 1.0000, 0.9025, 1.0000, 0.8689, 0.9678, 0.9873, 0.8874, 1.0000,\n",
      "        0.8928, 0.9970, 1.0000, 0.8643, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 0.9457, 1.0000, 1.0000, 0.8871, 0.9234, 0.9296, 1.0000,\n",
      "        1.0000, 1.0000, 0.9123, 1.0000, 1.0000, 0.0073, 0.8772, 1.0000, 0.8584,\n",
      "        0.9106, 1.0000, 0.8854, 1.0000, 0.8646, 1.0000, 1.0000, 0.9983, 0.9131,\n",
      "        0.8908, 0.8725, 0.0019, 0.9084, 0.8733, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9263, 1.0000, 1.0000, 0.9370, 0.8989, 0.9205, 0.9336, 0.8462, 0.9883,\n",
      "        1.0000, 0.8844, 1.0000, 1.0000, 0.8893, 0.9008, 1.0000, 1.0000, 0.9130,\n",
      "        0.9847, 0.9093, 1.0000, 0.9941, 1.0000, 0.8809, 0.9255, 1.0000, 0.9229,\n",
      "        1.0000, 1.0000, 1.0000, 0.8553, 1.0000, 0.9962],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8797, 0.9817, 0.9277, 0.9236, 0.9665, 1.0000, 1.0000, 0.9874, 1.0000,\n",
      "        0.9170, 0.9933, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9243, 1.0000, 1.0000, 1.0000, 0.1894, 0.9144, 1.0000, 0.3458,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.8579, 0.8766],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 9.1588e-01, 1.0000e+00, 9.9531e-01, 9.0147e-01, 8.6068e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.9470e-01, 1.0000e+00, 8.9727e-01, 8.4737e-01,\n",
      "        9.8577e-01, 8.6644e-01, 1.0000e+00, 8.6265e-01, 1.0000e+00, 9.6705e-01,\n",
      "        9.2668e-01, 1.0000e+00, 8.4921e-01, 1.0000e+00, 8.8298e-01, 1.0000e+00,\n",
      "        8.6830e-01, 9.1542e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5599e-09,\n",
      "        9.3879e-01, 9.5469e-01, 9.7001e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.8697, 1.0000, 1.0000, 1.0000, 1.0000, 0.8487,\n",
      "        1.0000, 0.9911, 0.0148, 0.3921, 1.0000, 1.0000, 1.0000, 0.8779, 0.9497,\n",
      "        0.8857, 0.0590, 1.0000, 1.0000, 0.0003, 0.9279, 0.9909, 0.8636, 0.9465,\n",
      "        1.0000, 0.9543, 0.9142, 1.0000, 0.8664, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9361, 0.8831, 1.0000, 0.9322, 0.9033, 0.9311, 0.8575, 1.0000, 1.0000,\n",
      "        0.9907, 0.9501, 0.8583, 1.0000, 1.0000, 0.0009, 1.0000, 0.9645, 1.0000,\n",
      "        1.0000, 0.8735, 1.0000, 1.0000, 0.8588, 1.0000, 1.0000, 0.8800, 0.9872,\n",
      "        0.9488, 0.8789, 0.1137, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.6909e-01, 8.4195e-01, 9.4763e-01, 9.7200e-01, 9.6014e-01, 9.4526e-01,\n",
      "        9.8373e-01, 8.8758e-01, 1.0000e+00, 8.8978e-01, 9.6642e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.7227e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 8.4420e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.6591e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.4953e-01, 1.0000e+00, 9.3378e-01, 6.3945e-05,\n",
      "        8.8855e-01, 1.0000e+00, 8.4976e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.8910e-01, 9.8548e-01, 1.0000e+00, 1.0000e+00, 8.5567e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.8435e-01, 9.5427e-01, 9.7765e-01, 1.0000e+00, 1.0000e+00,\n",
      "        8.5475e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.7503e-01, 9.5371e-01,\n",
      "        9.0071e-01, 9.2333e-01, 9.3562e-01, 1.0000e+00, 1.0000e+00, 4.8778e-02,\n",
      "        9.7798e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.3911e-01, 9.2882e-07,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9642, 0.9509, 1.0000, 0.9366, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.8587, 1.0000, 1.0000, 1.0000, 0.8914, 0.8963, 1.0000, 0.9797, 0.9870,\n",
      "        0.8713, 0.9650, 1.0000, 1.0000, 1.0000, 0.9613, 1.0000, 0.8993, 1.0000,\n",
      "        0.8768, 0.9008, 0.0073, 0.9352, 1.0000, 0.9672],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8566, 0.8652, 1.0000, 1.0000, 1.0000, 1.0000, 0.9276, 0.8491, 1.0000,\n",
      "        0.9572, 1.0000, 0.9020, 1.0000, 0.8554, 0.0007, 0.9665, 1.0000, 1.0000,\n",
      "        1.0000, 0.9773, 0.9250, 0.9812, 0.9135, 1.0000, 1.0000, 0.8571, 0.8588,\n",
      "        0.9008, 0.9274, 1.0000, 1.0000, 0.9367, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9542, 0.8489, 0.9551, 1.0000, 1.0000, 1.0000, 1.0000, 0.9730,\n",
      "        1.0000, 1.0000, 0.9660, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9337, 0.9303, 0.9321, 1.0000, 0.9847, 0.0362, 0.9773, 1.0000, 0.8983,\n",
      "        0.9153, 0.9902, 1.0000, 0.9856, 0.9564, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.0542e-01, 1.0000e+00, 9.1749e-01, 1.0000e+00, 9.1773e-01, 1.0000e+00,\n",
      "        9.9863e-01, 8.5214e-01, 1.0000e+00, 8.9916e-01, 1.5826e-01, 1.0000e+00,\n",
      "        9.2853e-01, 8.4689e-01, 1.0000e+00, 1.0000e+00, 8.4832e-01, 9.5994e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.2648e-01, 9.3798e-01, 1.0000e+00, 1.0000e+00,\n",
      "        9.5779e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.7491e-18,\n",
      "        9.5236e-01, 8.6981e-01, 8.7159e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9339, 0.8906, 0.8410, 0.9138,\n",
      "        1.0000, 0.9387, 0.9623, 0.8766, 0.9949, 1.0000, 1.0000, 1.0000, 0.9305,\n",
      "        1.0000, 1.0000, 1.0000, 0.9538, 1.0000, 1.0000, 0.9513, 0.8454, 1.0000,\n",
      "        0.9571, 1.0000, 1.0000, 1.0000, 0.9394, 0.9096],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9708, 1.0000, 1.0000, 1.0000, 0.9851, 0.9247, 1.0000, 1.0000, 1.0000,\n",
      "        0.8592, 0.9238, 1.0000, 0.9568, 0.8617, 1.0000, 0.9007, 1.0000, 0.9776,\n",
      "        1.0000, 0.9330, 1.0000, 1.0000, 1.0000, 0.2566, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.8656, 1.0000, 1.0000, 0.8973, 0.9565],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.8656, 1.0000, 0.8615, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9536, 0.8532, 1.0000, 0.9099,\n",
      "        1.0000, 0.9535, 1.0000, 1.0000, 1.0000, 0.1190, 1.0000, 1.0000, 0.9654,\n",
      "        0.9910, 1.0000, 1.0000, 0.8594, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9189, 0.8903, 1.0000, 1.0000, 0.9269, 0.8596, 1.0000, 0.9599,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.8669, 1.0000, 1.0000, 1.0000, 0.8927,\n",
      "        1.0000, 0.8493, 1.0000, 1.0000, 1.0000, 0.0972, 1.0000, 0.9446, 1.0000,\n",
      "        1.0000, 0.8687, 1.0000, 0.8942, 0.8809, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9439, 0.9589, 0.9276, 1.0000, 0.9500, 1.0000, 0.9439, 1.0000, 0.8419,\n",
      "        1.0000, 0.8506, 1.0000, 1.0000, 0.9383, 0.9536, 1.0000, 1.0000, 1.0000,\n",
      "        0.9772, 1.0000, 0.9006, 0.8424, 1.0000, 1.0000, 1.0000, 0.8638, 0.9307,\n",
      "        0.9014, 1.0000, 0.8441, 0.9778, 1.0000, 0.8863],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 0.9144, 1.0000, 1.0000, 0.8960, 1.0000, 1.0000, 0.8498,\n",
      "        1.0000, 1.0000, 0.8932, 0.9042, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.3409, 1.0000, 0.9307, 0.9733,\n",
      "        0.8660, 1.0000, 1.0000, 1.0000, 0.8952, 0.8952],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8771, 0.8422, 0.8456, 1.0000, 1.0000, 0.9840, 1.0000, 0.8703,\n",
      "        0.9221, 1.0000, 1.0000, 0.9706, 1.0000, 1.0000, 0.9463, 0.8550, 1.0000,\n",
      "        0.9690, 0.8926, 0.9528, 1.0000, 1.0000, 0.0860, 0.8527, 0.8902, 0.1263,\n",
      "        1.0000, 0.9391, 1.0000, 0.9467, 0.8410, 0.8556],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "0 0.053343839943408966\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8616, 1.0000, 1.0000, 1.0000, 1.0000, 0.8998, 1.0000, 0.9764, 1.0000,\n",
      "        0.9949, 1.0000, 1.0000, 1.0000, 0.8829, 1.0000, 0.8993, 0.9079, 1.0000,\n",
      "        1.0000, 0.9744, 1.0000, 0.9344, 0.9033, 0.9631, 0.9972, 1.0000, 0.9788,\n",
      "        1.0000, 1.0000, 0.9640, 1.0000, 1.0000, 0.8559],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
      "torch.Size([33])\n",
      "tensor([8.5972e-01, 9.6169e-01, 1.0000e+00, 8.6589e-01, 8.4198e-01, 1.0000e+00,\n",
      "        9.1550e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0519e-01,\n",
      "        1.0000e+00, 1.0000e+00, 8.6548e-01, 1.0000e+00, 9.5452e-01, 9.4956e-01,\n",
      "        9.0602e-01, 1.0000e+00, 8.1097e-01, 3.4541e-06, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.3524e-01, 9.3333e-01, 9.8132e-01, 9.9950e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9794, 1.0000, 1.0000, 0.8670, 1.0000, 0.8984, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 0.8646, 0.9778, 1.0000, 0.8918, 0.9830, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8905, 0.9661, 0.0003, 1.0000,\n",
      "        0.8997, 0.8538, 1.0000, 1.0000, 0.9175, 0.9328],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9925, 1.0000, 1.0000, 1.0000, 0.9498, 1.0000, 1.0000, 0.8407, 1.0000,\n",
      "        1.0000, 0.9031, 1.0000, 1.0000, 0.8433, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.8440, 1.0000, 1.0000, 0.9758, 1.0000, 0.8852, 0.8828, 1.0000, 1.0000,\n",
      "        0.8967, 1.0000, 0.9059, 1.0000, 0.9086, 0.8808],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 8.9534e-01, 1.0000e+00, 1.0000e+00, 9.0590e-01, 1.0000e+00,\n",
      "        1.0000e+00, 9.8079e-01, 1.8547e-04, 8.9592e-01, 8.5220e-01, 8.9748e-01,\n",
      "        9.6579e-01, 1.0000e+00, 1.0077e-03, 9.8128e-01, 1.0000e+00, 1.7293e-02,\n",
      "        1.0000e+00, 8.8033e-01, 8.7473e-01, 9.7762e-01, 9.7778e-01, 9.8482e-01,\n",
      "        1.0000e+00, 1.4335e-07, 3.2076e-03, 9.1000e-01, 1.0000e+00, 8.5314e-01,\n",
      "        1.0000e+00, 8.9896e-01, 9.8616e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8532, 1.0000, 1.0000, 0.9024, 0.9063, 1.0000, 0.8421, 0.8934, 0.8531,\n",
      "        1.0000, 0.8447, 0.9909, 0.9779, 0.9125, 1.0000, 0.9628, 1.0000, 0.9396,\n",
      "        0.8861, 0.9386, 1.0000, 0.9782, 1.0000, 0.9733, 0.9597, 0.9675, 1.0000,\n",
      "        1.0000, 0.9877, 1.0000, 1.0000, 0.9362, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8448, 0.9018, 0.9968, 1.0000, 0.3634, 1.0000, 0.8484, 0.9886, 0.9688,\n",
      "        1.0000, 0.9656, 0.8736, 0.0951, 0.0113, 0.8660, 0.9017, 0.9581, 1.0000,\n",
      "        1.0000, 0.9479, 0.9346, 0.9621, 1.0000, 1.0000, 0.9880, 0.9243, 1.0000,\n",
      "        0.9685, 1.0000, 1.0000, 1.0000, 1.0000, 0.8524],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9777, 0.9813, 1.0000, 0.9101, 0.8586, 0.9003, 0.8973, 0.9529, 0.8605,\n",
      "        0.8589, 0.8735, 1.0000, 1.0000, 0.9495, 1.0000, 0.9245, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.8553, 0.9227, 0.9215, 1.0000, 0.9157, 1.0000, 1.0000,\n",
      "        0.8571, 1.0000, 0.0031, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9347, 1.0000, 0.9673, 0.9605, 0.9312, 0.9332, 0.8686, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9122, 1.0000, 1.0000, 0.9552, 0.9337, 0.9658, 1.0000,\n",
      "        0.8590, 0.8815, 0.8952, 1.0000, 0.8883, 1.0000, 0.9331, 0.0001, 1.0000,\n",
      "        1.0000, 1.0000, 0.8693, 0.9801, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9456, 1.0000, 0.8578, 0.9312, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.8639, 1.0000, 1.0000, 1.0000, 0.0007,\n",
      "        1.0000, 0.9969, 1.0000, 1.0000, 0.9527, 0.9283, 1.0000, 1.0000, 0.0106,\n",
      "        1.0000, 0.9186, 0.8604, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6518e-01, 9.6821e-01, 1.0000e+00,\n",
      "        9.4764e-01, 9.5574e-01, 6.1248e-04, 9.4190e-01, 9.3889e-01, 1.0000e+00,\n",
      "        9.6818e-01, 9.3357e-01, 6.8780e-07, 9.6885e-01, 1.0000e+00, 2.1200e-02,\n",
      "        9.4913e-01, 9.8817e-01, 1.0000e+00, 8.8378e-01, 8.7335e-01, 1.0000e+00,\n",
      "        8.6607e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        8.9453e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.8605e-01, 9.8157e-01, 9.2149e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0222e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.7093e-01, 1.0000e+00, 8.2987e-03, 9.6719e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 8.4963e-01, 1.0000e+00, 9.0739e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8304e-01, 1.0000e+00, 9.2620e-12,\n",
      "        8.8315e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8565, 1.0000, 0.9237, 1.0000, 1.0000, 0.8827, 0.9295, 1.0000, 0.8680,\n",
      "        0.9060, 1.0000, 0.8634, 1.0000, 1.0000, 1.0000, 1.0000, 0.9749, 1.0000,\n",
      "        0.9176, 0.8967, 1.0000, 0.8749, 1.0000, 0.9837, 1.0000, 1.0000, 0.9293,\n",
      "        0.9252, 1.0000, 1.0000, 1.0000, 1.0000, 0.8763],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8638, 0.9549, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9477,\n",
      "        1.0000, 0.9794, 0.9012, 1.0000, 1.0000, 0.8435, 0.9148, 1.0000, 0.9574,\n",
      "        1.0000, 0.9306, 1.0000, 0.9211, 1.0000, 0.9541, 0.9348, 1.0000, 1.0000,\n",
      "        1.0000, 0.9566, 0.9935, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.6495e-01, 8.9421e-01, 8.4522e-01,\n",
      "        1.0000e+00, 1.0000e+00, 4.4802e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.7283e-01, 1.0000e+00, 9.6698e-01, 1.0000e+00, 4.1777e-06,\n",
      "        8.5601e-01, 8.7334e-01, 9.9307e-01, 1.0000e+00, 1.0000e+00, 9.1416e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6775e-01, 1.0000e+00, 9.0620e-01,\n",
      "        9.2052e-01, 1.0000e+00, 8.7835e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.0521e-01, 9.4924e-01, 1.0000e+00, 1.0000e+00, 9.6675e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.4223e-01, 1.0000e+00, 1.0000e+00, 8.5169e-01, 1.0000e+00,\n",
      "        9.7364e-01, 8.9516e-01, 1.0000e+00, 9.6704e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.8732e-01, 9.7969e-01, 1.0000e+00, 9.5268e-01, 1.0000e+00,\n",
      "        8.4238e-01, 8.3667e-08, 3.7145e-01, 9.5199e-01, 8.7300e-01, 1.3291e-02,\n",
      "        8.4288e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8442e-01, 9.4784e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0135e-05, 1.0000e+00, 9.1120e-01, 1.0000e+00,\n",
      "        9.5617e-01, 1.0000e+00, 1.0000e+00, 9.0526e-01, 1.0000e+00, 2.6884e-07,\n",
      "        9.1293e-01, 1.0000e+00, 8.7410e-01, 9.3950e-01, 9.0448e-01, 9.2818e-01,\n",
      "        9.4811e-01, 5.5220e-01, 1.0658e-01, 8.9867e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.0499e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9812, 0.9537, 1.0000, 0.8740, 1.0000, 1.0000, 1.0000, 1.0000, 0.0281,\n",
      "        0.9770, 0.9169, 0.9186, 1.0000, 1.0000, 0.0046, 0.9992, 0.9085, 1.0000,\n",
      "        0.8953, 1.0000, 1.0000, 1.0000, 0.9993, 0.8474, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9221, 0.8451, 0.8557, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.8625, 1.0000, 0.8417, 1.0000, 0.9432, 0.9708, 0.9009, 0.0606,\n",
      "        1.0000, 0.9457, 1.0000, 0.9955, 0.8808, 0.0006, 0.9057, 0.8504, 0.1056,\n",
      "        1.0000, 1.0000, 1.0000, 0.9448, 0.8718, 0.9145, 1.0000, 1.0000, 0.0104,\n",
      "        0.8906, 0.8769, 1.0000, 0.8684, 0.9498, 0.8433],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8614, 1.0000, 1.0000, 0.9533, 0.8959, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9506, 1.0000, 0.8900, 1.0000, 0.8477, 0.0013, 1.0000, 1.0000, 0.0013,\n",
      "        1.0000, 0.9287, 1.0000, 1.0000, 0.9352, 0.9979, 0.8892, 1.0000, 1.0000,\n",
      "        1.0000, 0.9331, 0.9505, 0.8751, 0.9176, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "tensor([0.9319, 0.9480, 0.9065, 1.0000, 1.0000, 0.8415, 0.9958, 0.9187, 0.0010,\n",
      "        1.0000, 0.9392, 0.9104, 1.0000, 0.9097, 1.0000, 1.0000, 0.8955, 1.0000,\n",
      "        0.8949, 1.0000, 1.0000, 0.9314, 1.0000, 1.0000, 0.9099, 0.0079, 0.0780,\n",
      "        1.0000, 1.0000, 0.9874, 0.9671, 0.9689, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 8.6454e-01, 9.7280e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.2002e-01, 9.9230e-01, 7.2551e-05, 9.4659e-01, 1.0000e+00, 1.0000e+00,\n",
      "        9.2880e-01, 9.8930e-01, 4.2453e-02, 1.0000e+00, 9.9605e-01, 1.0000e+00,\n",
      "        1.0000e+00, 9.0016e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.6485e-05, 1.4113e-02, 9.3325e-01, 1.0000e+00, 1.8466e-01,\n",
      "        8.7420e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0764e-01, 8.9140e-01, 9.2851e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0295e-01, 1.0000e+00, 1.6788e-01, 9.0163e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0896e-01, 8.8243e-01, 1.3799e-05,\n",
      "        8.7647e-01, 8.8515e-01, 1.0000e+00, 1.0000e+00, 9.5952e-01, 9.5979e-01,\n",
      "        1.0000e+00, 2.2643e-08, 1.0000e+00, 8.4716e-01, 9.0183e-01, 9.7967e-01,\n",
      "        9.9655e-01, 9.1097e-01, 8.4299e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8936, 1.0000, 0.9781, 1.0000,\n",
      "        0.9226, 1.0000, 0.8984, 0.8636, 0.8621, 1.0000, 0.8724, 1.0000, 0.4385,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.8858, 1.0000, 1.0000,\n",
      "        1.0000, 0.9015, 1.0000, 0.9273, 0.8948, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.2722e-01, 9.0197e-01, 1.0000e+00, 8.5602e-01, 1.0000e+00, 9.5064e-01,\n",
      "        8.6341e-01, 1.0000e+00, 7.0701e-05, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.0413e-01, 9.8553e-01, 1.1568e-03, 1.0000e+00, 1.0000e+00, 1.2125e-02,\n",
      "        1.0000e+00, 9.2809e-01, 8.4602e-01, 9.6223e-01, 1.0000e+00, 9.7673e-01,\n",
      "        8.8553e-01, 1.0000e+00, 2.8609e-02, 9.2655e-01, 8.7906e-01, 8.9657e-01,\n",
      "        9.6354e-01, 8.5798e-01, 9.7601e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9041, 1.0000, 1.0000, 0.9350, 0.8952, 1.0000, 1.0000, 1.0000, 0.0039,\n",
      "        1.0000, 1.0000, 1.0000, 0.8759, 0.9344, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9758, 1.0000, 1.0000, 0.8494, 1.0000, 0.9723, 0.8568, 1.0000, 0.0452,\n",
      "        1.0000, 0.9480, 0.0711, 0.8596, 1.0000, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.0706e-01, 9.3678e-01, 1.0000e+00, 1.0000e+00, 8.9993e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.7678e-01, 1.0000e+00, 9.2877e-01, 9.4133e-01, 8.5469e-01,\n",
      "        8.7318e-01, 1.0000e+00, 1.0000e+00, 9.3117e-01, 1.0000e+00, 1.0000e+00,\n",
      "        9.6975e-01, 1.0000e+00, 8.6460e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 2.5309e-06, 7.8704e-02, 9.1855e-01, 9.5305e-01, 1.0000e+00,\n",
      "        9.4613e-01, 9.8163e-01, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.8919, 0.9683, 0.9834, 1.0000, 0.8411, 0.8432, 1.0000, 0.9317, 1.0000,\n",
      "        0.8955, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.4053,\n",
      "        1.0000, 0.9265, 1.0000, 1.0000, 0.8437, 1.0000, 1.0000, 1.0000, 0.0364,\n",
      "        0.8798, 0.8662, 0.9280, 0.8655, 0.8738, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.6233e-01, 8.8118e-01, 1.0000e+00, 9.3292e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.7136e-01, 8.8900e-01, 3.2268e-06, 1.0000e+00, 9.6556e-01, 7.3455e-02,\n",
      "        9.9647e-01, 9.6567e-01, 1.0000e+00, 9.5861e-01, 8.8692e-01, 9.6573e-01,\n",
      "        8.9826e-01, 1.0000e+00, 5.6306e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.1410e-01, 3.7404e-01, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8533e-01, 1.0000e+00, 9.0839e-01,\n",
      "        9.5613e-01, 9.4944e-01, 1.0000e+00, 8.5802e-01, 1.0000e+00, 8.9925e-01,\n",
      "        1.0000e+00, 1.0000e+00, 5.8323e-04, 1.0000e+00, 9.3925e-01, 4.5184e-05,\n",
      "        1.0000e+00, 1.0000e+00, 9.0246e-01, 1.0000e+00, 8.6887e-01, 9.6777e-01,\n",
      "        9.8729e-01, 1.0000e+00, 1.0000e+00, 8.9278e-01, 9.9695e-01, 1.0000e+00,\n",
      "        8.6435e-01, 3.4509e-01, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 1.0000, 0.9457, 1.0000, 1.0000, 0.8871, 0.9234, 0.9296, 1.0000,\n",
      "        1.0000, 1.0000, 0.9123, 1.0000, 1.0000, 0.9515, 0.8772, 1.0000, 0.8584,\n",
      "        0.9106, 1.0000, 0.8854, 1.0000, 0.8646, 0.9977, 1.0000, 0.9983, 0.9131,\n",
      "        0.8908, 0.8725, 0.9600, 0.9084, 0.8733, 1.0000],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.2625e-01, 1.0000e+00, 1.0000e+00, 9.3700e-01, 8.9895e-01, 9.2046e-01,\n",
      "        9.3359e-01, 8.4624e-01, 1.0000e+00, 1.0000e+00, 2.5467e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.8927e-01, 5.7888e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.8472e-01, 9.0934e-01, 1.0000e+00, 9.9407e-01, 1.0000e+00, 8.8090e-01,\n",
      "        9.2552e-01, 1.6015e-03, 9.2292e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        8.5530e-01, 2.7748e-06, 9.9624e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.7968e-01, 9.8168e-01, 9.2770e-01, 9.2362e-01, 9.6645e-01, 1.0000e+00,\n",
      "        1.0000e+00, 9.8740e-01, 1.0000e+00, 9.1701e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0713e-02,\n",
      "        1.0000e+00, 9.2433e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.4461e-01,\n",
      "        9.1437e-01, 1.8737e-05, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 8.7657e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000, 0.9159, 1.0000, 0.9953, 0.9015, 0.8607, 1.0000, 1.0000, 0.0097,\n",
      "        1.0000, 0.8973, 0.8474, 0.9858, 0.8664, 0.0136, 0.8627, 1.0000, 1.0000,\n",
      "        0.9267, 1.0000, 0.8492, 1.0000, 0.8830, 1.0000, 0.8683, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.8947, 0.9388, 1.0000, 0.9700],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6969e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.9385e-01, 4.6743e-01, 1.0000e+00, 9.9111e-01, 9.7449e-01,\n",
      "        1.0000e+00, 9.8804e-01, 1.0000e+00, 9.3581e-01, 8.7787e-01, 2.1101e-06,\n",
      "        1.0000e+00, 9.5334e-01, 1.0000e+00, 1.0000e+00, 9.2550e-01, 9.2791e-01,\n",
      "        9.9086e-01, 1.0000e+00, 9.4650e-01, 1.0000e+00, 9.5433e-01, 1.0000e+00,\n",
      "        1.0000e+00, 2.5129e-06, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.3608e-01, 8.8306e-01, 1.0000e+00, 9.3225e-01, 9.0326e-01, 9.3113e-01,\n",
      "        8.5756e-01, 1.0000e+00, 9.0347e-05, 9.9075e-01, 9.5006e-01, 8.5830e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.4211e-03, 1.0000e+00, 9.6453e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.7347e-01, 1.0000e+00, 1.0000e+00, 8.5876e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.8719e-01, 9.4880e-01, 8.7893e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.6909e-01, 8.4195e-01, 9.4763e-01, 9.7200e-01, 9.6014e-01, 9.4526e-01,\n",
      "        9.8370e-01, 8.8759e-01, 2.4066e-02, 8.8978e-01, 9.6642e-01, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.2455e-06, 9.7227e-01, 1.0000e+00, 1.9015e-04,\n",
      "        1.0000e+00, 8.4424e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.6591e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.4953e-01, 1.0000e+00, 9.3378e-01, 1.0000e+00,\n",
      "        8.8855e-01, 1.2360e-05, 8.4976e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.8910e-01, 9.8548e-01, 1.0000e+00, 1.0000e+00, 8.5566e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.8435e-01, 1.0000e+00, 9.7765e-01, 1.0000e+00, 1.0000e+00,\n",
      "        8.5475e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.7506e-01, 9.4062e-03,\n",
      "        9.0072e-01, 9.2338e-01, 9.3561e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.7796e-01, 5.0757e-08, 9.2615e-01, 1.0000e+00, 9.3911e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.6279e-04, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9642, 0.9509, 1.0000, 0.9365, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.8587, 1.0000, 1.0000, 1.0000, 1.0000, 0.8963, 1.0000, 0.9797, 0.9870,\n",
      "        0.8713, 0.9649, 1.0000, 1.0000, 1.0000, 0.9613, 1.0000, 0.8993, 1.0000,\n",
      "        0.8768, 0.9008, 1.0000, 0.9352, 1.0000, 0.9672],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([8.5660e-01, 8.6516e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.2770e-01, 8.4911e-01, 1.0000e+00, 9.5719e-01, 1.0000e+00, 9.0202e-01,\n",
      "        1.0000e+00, 8.5532e-01, 2.7385e-03, 9.6651e-01, 1.0000e+00, 9.3018e-06,\n",
      "        1.0000e+00, 9.7722e-01, 9.2496e-01, 9.8122e-01, 9.1354e-01, 8.8524e-01,\n",
      "        1.0000e+00, 1.0000e+00, 8.5880e-01, 9.0079e-01, 9.2741e-01, 9.2572e-01,\n",
      "        1.0000e+00, 2.1771e-06, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 9.5421e-01, 8.4894e-01, 9.5506e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 9.0027e-02, 1.0000e+00, 1.0000e+00, 9.6604e-01,\n",
      "        1.0000e+00, 1.0000e+00, 3.5718e-04, 1.0000e+00, 1.0000e+00, 4.0999e-05,\n",
      "        9.3360e-01, 9.3041e-01, 9.3202e-01, 1.0000e+00, 9.8461e-01, 1.0000e+00,\n",
      "        9.7740e-01, 1.0000e+00, 8.9822e-01, 9.1532e-01, 9.9024e-01, 1.0000e+00,\n",
      "        9.8566e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([0.9054, 1.0000, 0.9175, 1.0000, 0.9177, 1.0000, 0.9985, 0.8521, 1.0000,\n",
      "        0.8992, 0.9037, 1.0000, 0.9285, 0.8468, 1.0000, 1.0000, 0.8484, 0.0052,\n",
      "        1.0000, 1.0000, 0.9265, 0.9380, 1.0000, 1.0000, 0.9578, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9707, 0.9524, 1.0000, 0.8716],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.3393e-01,\n",
      "        8.9072e-01, 8.4098e-01, 3.0584e-03, 1.0000e+00, 1.0000e+00, 9.6226e-01,\n",
      "        8.7655e-01, 9.9484e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 9.5387e-01, 1.0000e+00, 1.0000e+00,\n",
      "        9.5135e-01, 8.0046e-07, 1.0000e+00, 9.5718e-01, 1.0000e+00, 8.1977e-08,\n",
      "        1.0000e+00, 1.0000e+00, 9.0957e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.7081e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8522e-01, 9.2460e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 8.5916e-01, 2.1830e-01, 1.0000e+00,\n",
      "        9.5684e-01, 8.6181e-01, 1.0000e+00, 9.0073e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.3294e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 2.2755e-05, 1.0000e+00, 1.0000e+00, 8.6561e-01, 8.9419e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.5658e-01], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.6566e-01, 1.0000e+00,\n",
      "        8.6142e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 2.0817e-05, 8.5312e-01, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.5361e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.6129e-08, 9.6527e-01, 9.9087e-01, 1.0000e+00, 1.7853e-04,\n",
      "        8.5937e-01, 2.4183e-04, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([1.0000e+00, 9.1888e-01, 8.9022e-01, 1.0000e+00, 1.0000e+00, 9.2695e-01,\n",
      "        8.5956e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.0125e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.6701e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8546e-06,\n",
      "        1.0000e+00, 8.4926e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.4985e-04, 9.7038e-01, 1.0000e+00, 8.6877e-01, 1.0000e+00,\n",
      "        8.9427e-01, 1.0000e+00, 1.0000e+00], grad_fn=<ExpBackward>)\n",
      "torch.Size([33])\n",
      "tensor([0.0530, 0.0344, 0.0275, 0.5514, 0.1392, 0.0610, 0.4743, 0.0681, 0.2212,\n",
      "        0.5452, 0.7599, 0.1238, 0.4623, 0.4964, 0.2917, 0.1806, 0.0998, 0.2658,\n",
      "        0.2048, 0.7857, 0.4047, 0.3008, 0.1822, 0.2013, 0.9664, 0.4024, 0.8790,\n",
      "        0.1454, 0.0481, 0.0110, 0.0676, 0.2780, 0.0102])\n",
      "torch.Size([33])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.])\n",
      "torch.Size([33])\n",
      "tensor([9.4381e-01, 9.5884e-01, 9.2772e-01, 1.0000e+00, 9.5011e-01, 1.0000e+00,\n",
      "        9.4397e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 9.3824e-01, 3.6161e-02, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "        9.7714e-01, 1.0000e+00, 9.0050e-01, 8.4249e-01, 1.0000e+00, 8.7426e-01,\n",
      "        1.0000e+00, 1.9602e-08, 1.0000e+00, 9.0127e-01, 1.0000e+00, 1.0000e+00,\n",
      "        9.7776e-01, 6.4762e-03, 8.8620e-01], grad_fn=<ExpBackward>)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5a861eca7d6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# Forward pass : Compute predicted y by passing train data to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# Compute and print loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-e19e2fbdbcd2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    374\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    389\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    390\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    for train_data, train_label in train_dataloader:\n",
    "        # Squeeze the data [1, 33, 49], [1,5] to [33, 49], [5]\n",
    "        train_data = torch.squeeze(train_data)\n",
    "        train_label = torch.squeeze(train_label)\n",
    "        \n",
    "        # Forward pass : Compute predicted y by passing train data to the model\n",
    "        y_pred = model(train_data)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, train_label)\n",
    "        print(t, loss.item())\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
